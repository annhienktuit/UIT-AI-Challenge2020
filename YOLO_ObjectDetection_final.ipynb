{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_ObjectDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annhienktuit/UIT-AI-Challenge2020/blob/master/YOLO_ObjectDetection_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_alhvVEGy3D1",
        "colab_type": "text"
      },
      "source": [
        "Xây dựng bộ phát hiện đối tượng với thuật toán YOLOv3 được viết bằng thư viện Keras. Thư viện này bao gồm đầy đủ các module: phát hiện đối tượng với pre-trainded model, huấn luyện lại mô hình, phát hiện đối tượng ảnh trên ảnh/video/webcam.\n",
        "\n",
        "Đầu tiên, ta sẽ khởi tạo Google Colab với sử dụng 1 GPU. Sau đó thực hiện kết nối với Google Drive của tài khoản cá nhân như sau:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2zzYmnoEw_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "6c96a27a-7b9d-41d3-ac4f-483d80e3248f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug  7 12:40:05 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWYdIEs4GvaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8097caea-bdc7-4f71-acfd-3fff74486224"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "lab_path = \"/content/gdrive/My\\ Drive/AdvancedComputerVision/keras-yolo3\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BOqO01h5LfP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1da0581-aaad-4240-9c73-14b95c100634"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3bs8vR3NPn",
        "colab_type": "text"
      },
      "source": [
        "Sau đó, sử dụng git để clone thư mục project từ github của tác giả experiencor với đường dẫn như sau. Lưu ý rằng, ta nên đặt thực project kế bên file jupyter notebook này để tiện thao tác."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_PW5hu4IdXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "171af729-b52f-46fc-e2ab-6cc310b7bb08"
      },
      "source": [
        "!git clone https://github.com/experiencor/keras-yolo3.git $lab_path"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3'...\n",
            "remote: Enumerating objects: 220, done.\u001b[K\n",
            "remote: Total 220 (delta 0), reused 0 (delta 0), pack-reused 220\u001b[K\n",
            "Receiving objects: 100% (220/220), 91.27 KiB | 1.79 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ppso2Gj3vnV",
        "colab_type": "text"
      },
      "source": [
        "Sau đó tiến hành cài đặt các thư viện cần thiết để có thể sử dụng được keras-yolo3. Đây là bước thực hiện quan trọng vì thông thường các thư viện sẽ sử dụng các thư viện bên thứ 3 với các phiên bản cố định. Do đó, để đảm bảo thư viện keras-yolo3 sử dụng trơn tru thì ta sẽ cài đặt các thư viện kèm theo trong file requirements.txt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjQWjajkJBSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b93306d1-f2e9-4c16-e5d9-0ddfe96fdeef"
      },
      "source": [
        "!pip install -r $lab_path/requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: absl-py==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 2)) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting google-pasta==0.1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hCollecting grpcio==1.26.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/8f/f79c5c174bebece41f824dd7b1ba98da45dc2d4c373b38ac6a7f6a5acb5e/grpcio-1.26.0-cp36-cp36m-manylinux2010_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 6)) (2.10.0)\n",
            "Collecting Keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 30.7MB/s \n",
            "\u001b[?25hCollecting Keras-Applications==1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hCollecting Keras-Preprocessing==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hCollecting Markdown==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.4MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python==4.1.2.30 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 12)) (4.1.2.30)\n",
            "Collecting opt-einsum==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[?25hCollecting protobuf==3.11.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ac/838c8c8a5f33a58132dd2ad2a30329f6ae1614a9f56ffb79eaaf71a9d156/protobuf-3.11.2-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 37.0MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d9/ea9816aea31beeadccd03f1f8b625ecf8f645bd66744484d162d84803ce5/PyYAML-5.3.tar.gz (268kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 30.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 16)) (1.4.1)\n",
            "Collecting six==1.14.0\n",
            "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
            "Collecting tensorboard==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 33.6MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 41kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 21)) (1.1.0)\n",
            "Requirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 22)) (4.41.1)\n",
            "Collecting Werkzeug==0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 30.2MB/s \n",
            "\u001b[?25hCollecting wrapt==1.11.2\n",
            "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
            "Requirement already satisfied: setuptools>=36 in /usr/local/lib/python3.6/dist-packages (from Markdown==3.1.1->-r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 10)) (49.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->-r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 18)) (0.34.2)\n",
            "Building wheels for collected packages: gast, opt-einsum, PyYAML, wrapt\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=944b3941bbc028b3d50d693ab45b99e76eeb415f95bc7ce67c4759bff1399113\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-cp36-none-any.whl size=61682 sha256=9a5efbb0d6f55ed822427bbcc4c19219ed802b94a35489ed7a85983e13e66715\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3-cp36-cp36m-linux_x86_64.whl size=44229 sha256=06c4d3bd6e31188e9e5c5d1ebd163858d122bff61c9a69c6b8bf3245a0bf256b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/76/4d/a95b8dd7b452b69e8ed4f68b69e1b55e12c9c9624dd962b191\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl size=67530 sha256=bfac8bcfae434746ecb5e3561b9c0b58989db2046bd2ca65a79a77040893019b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
            "Successfully built gast opt-einsum PyYAML wrapt\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, six, google-pasta, grpcio, PyYAML, numpy, Keras-Preprocessing, Keras-Applications, Keras, Markdown, opt-einsum, protobuf, Werkzeug, tensorboard, tensorflow-estimator, wrapt, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Found existing installation: grpcio 1.30.0\n",
            "    Uninstalling grpcio-1.30.0:\n",
            "      Successfully uninstalled grpcio-1.30.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "  Found existing installation: Markdown 3.2.2\n",
            "    Uninstalling Markdown-3.2.2:\n",
            "      Successfully uninstalled Markdown-3.2.2\n",
            "  Found existing installation: opt-einsum 3.3.0\n",
            "    Uninstalling opt-einsum-3.3.0:\n",
            "      Successfully uninstalled opt-einsum-3.3.0\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "  Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: wrapt 1.12.1\n",
            "    Uninstalling wrapt-1.12.1:\n",
            "      Successfully uninstalled wrapt-1.12.1\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed Keras-2.3.1 Keras-Applications-1.0.8 Keras-Preprocessing-1.1.0 Markdown-3.1.1 PyYAML-5.3 Werkzeug-0.16.0 gast-0.2.2 google-pasta-0.1.8 grpcio-1.26.0 numpy-1.18.1 opt-einsum-3.1.0 protobuf-3.11.2 six-1.14.0 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 wrapt-1.11.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3eT3bTp56Hd",
        "colab_type": "text"
      },
      "source": [
        "## 1. Thử nghiệm với pretrained model của tác giả thuật toán YOLO.\n",
        "\n",
        "File mô hình huấn luyện sẵn được đặt ở đường dẫn sau https://pjreddie.com/media/files/yolov3.weights\n",
        "Lưu ý là file mô hình cần được đặt trong thư mục gốc của thư viện để tiện cho việc thực hiện."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLTQkJH1JR-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "edaa8d7b-a70a-4471-93f4-670bacab6824"
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights -O $lab_path/yolov3.weights"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-07 12:41:14--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘/content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/yolov3.weights’\n",
            "\n",
            "/content/gdrive/My  100%[===================>] 236.52M   397KB/s    in 9m 3s   \n",
            "\n",
            "2020-08-07 12:50:19 (446 KB/s) - ‘/content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDDqM_Xj6Xej",
        "colab_type": "text"
      },
      "source": [
        "Sau đó, ta tiến hành sử dụng pretrained model để phát hiện đối tượng trong ảnh cho trước. Sử dụng chương trình yolo3_one_file_to_detect_them_all.py với file mô hình đã download ở file trước đó để phát hiện các đối tượng trong ảnh. Tập dữ liệu các đối tượng phát hiện được lấy từ tập PASCAL VOC 2012.\n",
        "\n",
        "Ảnh kết quả phát hiện đối tượng trên pretrained model cho tập dữ liệu này được minh hoạ như ở hình sau:\n",
        "\n",
        "![alt text](https://i.imgur.com/6nun5fl.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9BdlFEySHM1",
        "colab_type": "text"
      },
      "source": [
        "**Sửa np.nan thành sys.maxsize và import sys**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLB2xdvzarZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2986757a-1c8d-46f9-fd11-057e851984bd"
      },
      "source": [
        "!python $lab_path/yolo3_one_file_to_detect_them_all.py -w $lab_path/yolov3.weights -i $lab_path/dog.jpg\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2020-08-07 12:51:38.554490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-07 12:51:38.609123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 12:51:38.609908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-07 12:51:38.633046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-07 12:51:38.855192: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-07 12:51:38.961658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-07 12:51:38.988600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-07 12:51:39.223215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-07 12:51:39.357197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-07 12:51:39.885480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-07 12:51:39.885731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 12:51:39.886635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 12:51:39.887379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-07 12:51:39.887811: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-08-07 12:51:39.893089: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2020-08-07 12:51:39.893340: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1676bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-07 12:51:39.893377: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-07 12:51:39.979505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 12:51:39.980424: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1676d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-07 12:51:39.980462: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-08-07 12:51:39.981762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 12:51:39.982669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-07 12:51:39.982770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-07 12:51:39.982823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-07 12:51:39.982892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-07 12:51:39.982958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-07 12:51:39.983004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-07 12:51:39.983045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-07 12:51:39.983087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-07 12:51:39.983219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 12:51:39.983989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 12:51:39.984704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-07 12:51:39.984818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-07 12:51:39.986283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-07 12:51:39.986319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-07 12:51:39.986348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-07 12:51:39.986538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 12:51:39.987373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 12:51:39.988146: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-07 12:51:39.988197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "loading weights of convolution #0\n",
            "loading weights of convolution #1\n",
            "loading weights of convolution #2\n",
            "loading weights of convolution #3\n",
            "no convolution #4\n",
            "loading weights of convolution #5\n",
            "loading weights of convolution #6\n",
            "loading weights of convolution #7\n",
            "no convolution #8\n",
            "loading weights of convolution #9\n",
            "loading weights of convolution #10\n",
            "no convolution #11\n",
            "loading weights of convolution #12\n",
            "loading weights of convolution #13\n",
            "loading weights of convolution #14\n",
            "no convolution #15\n",
            "loading weights of convolution #16\n",
            "loading weights of convolution #17\n",
            "no convolution #18\n",
            "loading weights of convolution #19\n",
            "loading weights of convolution #20\n",
            "no convolution #21\n",
            "loading weights of convolution #22\n",
            "loading weights of convolution #23\n",
            "no convolution #24\n",
            "loading weights of convolution #25\n",
            "loading weights of convolution #26\n",
            "no convolution #27\n",
            "loading weights of convolution #28\n",
            "loading weights of convolution #29\n",
            "no convolution #30\n",
            "loading weights of convolution #31\n",
            "loading weights of convolution #32\n",
            "no convolution #33\n",
            "loading weights of convolution #34\n",
            "loading weights of convolution #35\n",
            "no convolution #36\n",
            "loading weights of convolution #37\n",
            "loading weights of convolution #38\n",
            "loading weights of convolution #39\n",
            "no convolution #40\n",
            "loading weights of convolution #41\n",
            "loading weights of convolution #42\n",
            "no convolution #43\n",
            "loading weights of convolution #44\n",
            "loading weights of convolution #45\n",
            "no convolution #46\n",
            "loading weights of convolution #47\n",
            "loading weights of convolution #48\n",
            "no convolution #49\n",
            "loading weights of convolution #50\n",
            "loading weights of convolution #51\n",
            "no convolution #52\n",
            "loading weights of convolution #53\n",
            "loading weights of convolution #54\n",
            "no convolution #55\n",
            "loading weights of convolution #56\n",
            "loading weights of convolution #57\n",
            "no convolution #58\n",
            "loading weights of convolution #59\n",
            "loading weights of convolution #60\n",
            "no convolution #61\n",
            "loading weights of convolution #62\n",
            "loading weights of convolution #63\n",
            "loading weights of convolution #64\n",
            "no convolution #65\n",
            "loading weights of convolution #66\n",
            "loading weights of convolution #67\n",
            "no convolution #68\n",
            "loading weights of convolution #69\n",
            "loading weights of convolution #70\n",
            "no convolution #71\n",
            "loading weights of convolution #72\n",
            "loading weights of convolution #73\n",
            "no convolution #74\n",
            "loading weights of convolution #75\n",
            "loading weights of convolution #76\n",
            "loading weights of convolution #77\n",
            "loading weights of convolution #78\n",
            "loading weights of convolution #79\n",
            "loading weights of convolution #80\n",
            "loading weights of convolution #81\n",
            "no convolution #82\n",
            "no convolution #83\n",
            "loading weights of convolution #84\n",
            "no convolution #85\n",
            "no convolution #86\n",
            "loading weights of convolution #87\n",
            "loading weights of convolution #88\n",
            "loading weights of convolution #89\n",
            "loading weights of convolution #90\n",
            "loading weights of convolution #91\n",
            "loading weights of convolution #92\n",
            "loading weights of convolution #93\n",
            "no convolution #94\n",
            "no convolution #95\n",
            "loading weights of convolution #96\n",
            "no convolution #97\n",
            "no convolution #98\n",
            "loading weights of convolution #99\n",
            "loading weights of convolution #100\n",
            "loading weights of convolution #101\n",
            "loading weights of convolution #102\n",
            "loading weights of convolution #103\n",
            "loading weights of convolution #104\n",
            "loading weights of convolution #105\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "2020-08-07 12:52:37.259476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-07 12:52:41.296033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "dog: 97.04445004463196%\n",
            "dog: 97.64495491981506%\n",
            "dog: 99.17258024215698%\n",
            "dog: 64.52338099479675%\n",
            "dog: 87.50191330909729%\n",
            "dog: 93.91770362854004%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGr9clen11Bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image('/content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3_1/dog_detected.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "190SzOsZ7LUG",
        "colab_type": "text"
      },
      "source": [
        "#2. Huấn luyện dữ liệu với keras-yolo3\n",
        "\n",
        "![alt text](https://i.imgur.com/45SRniL.jpg)\n",
        "\n",
        "Bước tiếp theo, ta sẽ tiến hành huấn luyện trên tập dữ liệu mới là gấu mèo (raccoon). Tập dữ liệu này được tải từ https://github.com/experiencor/raccoon_dataset.git\n",
        "\n",
        "Lưu ý rằng, ta sẽ chỉ sử dụng 2 thư mục của github này là images và annotations. Trong đó,\n",
        "\n",
        "*   images: thư mục chứa các ảnh về gấu mèo\n",
        "*   annotations: tương ứng với từng file ảnh của thư mục images, ta có một file .xml chứa thông tin về vị trí chính xác của đối tượng (gấu mèo) trong ảnh.\n",
        "\n",
        "Các bạn nên xem kỹ định dạng của các file XML này để biết cấu trúc file gán nhãn phục vụ cho việc thực hiện đồ án sau này.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuTscS1_eRge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "824f7d45-ffab-41c1-881d-170c349d8a30"
      },
      "source": [
        "!git clone https://github.com/experiencor/raccoon_dataset.git $lab_path/raccoon_dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/raccoon_dataset'...\n",
            "remote: Enumerating objects: 646, done.\u001b[K\n",
            "remote: Total 646 (delta 0), reused 0 (delta 0), pack-reused 646\n",
            "Receiving objects: 100% (646/646), 48.00 MiB | 14.29 MiB/s, done.\n",
            "Resolving deltas: 100% (412/412), done.\n",
            "Checking out files: 100% (419/419), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ2W6IpbyQm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jwGhNHHBmr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIgrFV1B_gyo",
        "colab_type": "text"
      },
      "source": [
        "Một file khác cũng rất quan trọng của các mô hình huấn luyện học sâu nói chung và YOLO nói riêng là file cấu hình (config) các tham số khi huấn luyện.\n",
        "\n",
        "Trong thư viện này, file config được đặt trong thư mục /zoo. Ví dụ như config_raccoon.json. Các tham số cơ bản của file config như:\n",
        "- Đường dẫn đến thư mục train, validation (mặc định chia tỉ lệ train:validation = 8:2 nếu không có tham số gắn sẵn)\n",
        "- GPU sử dụng để huấn luyện\n",
        "- File pretrained cho tập image net backend.h5\n",
        "- Learning rate\n",
        "- Batch size\n",
        "\n",
        "Sau khi đã cấu hình file config, ta sẽ tiến hành huấn luyện:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElBnlnryy3el",
        "colab_type": "text"
      },
      "source": [
        "Để chương trình train có thể chạy được ta phải tải thêm file backend.h5 chứa pretrained model của backbone model và đặt ở thư mục lab_path:\n",
        "https://drive.google.com/file/d/1f3Ylajkfg69iXc5159oJlYsq-9D_Px50/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM2b6ooPSVXD",
        "colab_type": "text"
      },
      "source": [
        "**Chỉnh về 1 GPU, chỉnh path cho annotation và images(cả valid), chỉnh batch size về 8**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc2dmMk1rjWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60068e51-351a-4423-e88c-96c4adccb192"
      },
      "source": [
        "!python $lab_path/train.py -c $lab_path/zoo/config_raccoon.json"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2020-08-07 13:06:06.194807: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-08-07 13:06:06.199906: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2020-08-07 13:06:06.200207: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1798bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-07 13:06:06.200301: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-07 13:06:06.202179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-07 13:06:06.273091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 13:06:06.273915: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1798d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-07 13:06:06.273951: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-08-07 13:06:06.274128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 13:06:06.274804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-07 13:06:06.275188: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-07 13:06:06.276716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-07 13:06:06.277930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-07 13:06:06.278306: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-07 13:06:06.279881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-07 13:06:06.281049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-07 13:06:06.284996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-07 13:06:06.285143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 13:06:06.285930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 13:06:06.286632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-07 13:06:06.286708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-07 13:06:06.288128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-07 13:06:06.288164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-07 13:06:06.288183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-07 13:06:06.288377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 13:06:06.289174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 13:06:06.290062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10297 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/train.py:26: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
            "\n",
            "Seen labels: \t{'raccoon': 173}\n",
            "\n",
            "Given labels: \t['raccoon']\n",
            "\n",
            "Training on: \t['raccoon']\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/yolo.py:26: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/yolo.py:151: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "Epoch 1/103\n",
            "2020-08-07 13:07:08.753502: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 154140672 exceeds 10% of system memory.\n",
            "2020-08-07 13:07:09.106984: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 154140672 exceeds 10% of system memory.\n",
            "2020-08-07 13:07:09.609479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-07 13:07:10.497358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/callbacks.py:19: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "2020-08-07 13:08:05.480875: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            " - 112s - loss: 694.7666 - yolo_layer_1_loss: 92.3512 - yolo_layer_2_loss: 204.1593 - yolo_layer_3_loss: 398.2561\n",
            "\n",
            "Epoch 00001: loss improved from inf to 694.76659, saving model to raccoon.h5\n",
            "Epoch 2/103\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            " - 68s - loss: 171.9081 - yolo_layer_1_loss: 26.2592 - yolo_layer_2_loss: 46.3426 - yolo_layer_3_loss: 99.3063\n",
            "\n",
            "Epoch 00002: loss improved from 694.76659 to 171.90812, saving model to raccoon.h5\n",
            "Epoch 3/103\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            " - 52s - loss: 86.6353 - yolo_layer_1_loss: 16.8668 - yolo_layer_2_loss: 22.9020 - yolo_layer_3_loss: 46.8666\n",
            "\n",
            "Epoch 00003: loss improved from 171.90812 to 86.63534, saving model to raccoon.h5\n",
            "Epoch 4/103\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            " - 65s - loss: 21.3962 - yolo_layer_1_loss: 8.8444 - yolo_layer_2_loss: 3.5509 - yolo_layer_3_loss: 9.0008\n",
            "\n",
            "Epoch 00004: loss improved from 86.63534 to 21.39616, saving model to raccoon.h5\n",
            "Epoch 5/103\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            " - 68s - loss: 8.9141 - yolo_layer_1_loss: 5.6824 - yolo_layer_2_loss: 1.7295 - yolo_layer_3_loss: 1.5022\n",
            "\n",
            "Epoch 00005: loss improved from 21.39616 to 8.91407, saving model to raccoon.h5\n",
            "Epoch 6/103\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            " - 79s - loss: 6.3814 - yolo_layer_1_loss: 4.6450 - yolo_layer_2_loss: 0.8874 - yolo_layer_3_loss: 0.8490\n",
            "\n",
            "Epoch 00006: loss improved from 8.91407 to 6.38142, saving model to raccoon.h5\n",
            "Epoch 7/103\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            " - 57s - loss: 6.2886 - yolo_layer_1_loss: 4.0263 - yolo_layer_2_loss: 1.7520 - yolo_layer_3_loss: 0.5104\n",
            "\n",
            "Epoch 00007: loss improved from 6.38142 to 6.28864, saving model to raccoon.h5\n",
            "Epoch 8/103\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            " - 73s - loss: 5.5942 - yolo_layer_1_loss: 4.0115 - yolo_layer_2_loss: 1.0171 - yolo_layer_3_loss: 0.5656\n",
            "\n",
            "Epoch 00008: loss improved from 6.28864 to 5.59421, saving model to raccoon.h5\n",
            "Epoch 9/103\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            " - 59s - loss: 5.1588 - yolo_layer_1_loss: 3.4993 - yolo_layer_2_loss: 1.4171 - yolo_layer_3_loss: 0.2424\n",
            "\n",
            "Epoch 00009: loss improved from 5.59421 to 5.15884, saving model to raccoon.h5\n",
            "Epoch 10/103\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            " - 72s - loss: 4.7013 - yolo_layer_1_loss: 3.5772 - yolo_layer_2_loss: 0.7311 - yolo_layer_3_loss: 0.3930\n",
            "\n",
            "Epoch 00010: loss improved from 5.15884 to 4.70128, saving model to raccoon.h5\n",
            "Epoch 11/103\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            " - 66s - loss: 4.1570 - yolo_layer_1_loss: 2.8933 - yolo_layer_2_loss: 0.6988 - yolo_layer_3_loss: 0.5649\n",
            "\n",
            "Epoch 00011: loss improved from 4.70128 to 4.15697, saving model to raccoon.h5\n",
            "Epoch 12/103\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            " - 73s - loss: 5.1069 - yolo_layer_1_loss: 3.6264 - yolo_layer_2_loss: 1.0494 - yolo_layer_3_loss: 0.4311\n",
            "\n",
            "Epoch 00012: loss did not improve from 4.15697\n",
            "Epoch 13/103\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            " - 65s - loss: 3.9439 - yolo_layer_1_loss: 2.9693 - yolo_layer_2_loss: 0.6507 - yolo_layer_3_loss: 0.3238\n",
            "\n",
            "Epoch 00013: loss improved from 4.15697 to 3.94389, saving model to raccoon.h5\n",
            "Epoch 14/103\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            " - 65s - loss: 3.9803 - yolo_layer_1_loss: 2.5802 - yolo_layer_2_loss: 0.9720 - yolo_layer_3_loss: 0.4282\n",
            "\n",
            "Epoch 00014: loss did not improve from 3.94389\n",
            "Epoch 15/103\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            " - 64s - loss: 3.7398 - yolo_layer_1_loss: 2.7423 - yolo_layer_2_loss: 0.7872 - yolo_layer_3_loss: 0.2103\n",
            "\n",
            "Epoch 00015: loss improved from 3.94389 to 3.73981, saving model to raccoon.h5\n",
            "Epoch 16/103\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            " - 58s - loss: 4.0791 - yolo_layer_1_loss: 2.6391 - yolo_layer_2_loss: 1.1532 - yolo_layer_3_loss: 0.2868\n",
            "\n",
            "Epoch 00016: loss did not improve from 3.73981\n",
            "Epoch 17/103\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            "resizing:  320 320\n",
            " - 74s - loss: 3.5903 - yolo_layer_1_loss: 2.3241 - yolo_layer_2_loss: 0.9871 - yolo_layer_3_loss: 0.2790\n",
            "\n",
            "Epoch 00017: loss improved from 3.73981 to 3.59029, saving model to raccoon.h5\n",
            "Epoch 18/103\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            " - 61s - loss: 4.3591 - yolo_layer_1_loss: 2.7689 - yolo_layer_2_loss: 1.5299 - yolo_layer_3_loss: 0.0603\n",
            "\n",
            "Epoch 00018: loss did not improve from 3.59029\n",
            "Epoch 19/103\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            " - 65s - loss: 3.3689 - yolo_layer_1_loss: 2.1908 - yolo_layer_2_loss: 1.1213 - yolo_layer_3_loss: 0.0567\n",
            "\n",
            "Epoch 00019: loss improved from 3.59029 to 3.36886, saving model to raccoon.h5\n",
            "Epoch 20/103\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            " - 67s - loss: 3.5211 - yolo_layer_1_loss: 2.3614 - yolo_layer_2_loss: 0.9065 - yolo_layer_3_loss: 0.2532\n",
            "\n",
            "Epoch 00020: loss did not improve from 3.36886\n",
            "Epoch 21/103\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            " - 77s - loss: 3.0555 - yolo_layer_1_loss: 2.0409 - yolo_layer_2_loss: 0.8833 - yolo_layer_3_loss: 0.1313\n",
            "\n",
            "Epoch 00021: loss improved from 3.36886 to 3.05546, saving model to raccoon.h5\n",
            "Epoch 22/103\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            " - 62s - loss: 3.6803 - yolo_layer_1_loss: 2.2681 - yolo_layer_2_loss: 1.0848 - yolo_layer_3_loss: 0.3274\n",
            "\n",
            "Epoch 00022: loss did not improve from 3.05546\n",
            "Epoch 23/103\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            " - 66s - loss: 3.4128 - yolo_layer_1_loss: 2.1272 - yolo_layer_2_loss: 1.1650 - yolo_layer_3_loss: 0.1206\n",
            "\n",
            "Epoch 00023: loss did not improve from 3.05546\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 24/103\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            " - 62s - loss: 3.5411 - yolo_layer_1_loss: 1.8953 - yolo_layer_2_loss: 1.4074 - yolo_layer_3_loss: 0.2384\n",
            "\n",
            "Epoch 00024: loss did not improve from 3.05546\n",
            "Epoch 25/103\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            " - 60s - loss: 3.3299 - yolo_layer_1_loss: 1.7046 - yolo_layer_2_loss: 1.3081 - yolo_layer_3_loss: 0.3173\n",
            "\n",
            "Epoch 00025: loss did not improve from 3.05546\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 26/103\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            " - 65s - loss: 3.0362 - yolo_layer_1_loss: 1.4029 - yolo_layer_2_loss: 1.3098 - yolo_layer_3_loss: 0.3235\n",
            "\n",
            "Epoch 00026: loss improved from 3.05546 to 3.03622, saving model to raccoon.h5\n",
            "Epoch 27/103\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            "resizing:  320 320\n",
            " - 67s - loss: 2.7038 - yolo_layer_1_loss: 1.5878 - yolo_layer_2_loss: 0.9978 - yolo_layer_3_loss: 0.1182\n",
            "\n",
            "Epoch 00027: loss improved from 3.03622 to 2.70379, saving model to raccoon.h5\n",
            "Epoch 28/103\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            " - 65s - loss: 2.7163 - yolo_layer_1_loss: 1.4136 - yolo_layer_2_loss: 0.9448 - yolo_layer_3_loss: 0.3579\n",
            "\n",
            "Epoch 00028: loss did not improve from 2.70379\n",
            "Epoch 29/103\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            " - 60s - loss: 3.3775 - yolo_layer_1_loss: 1.4105 - yolo_layer_2_loss: 1.7298 - yolo_layer_3_loss: 0.2372\n",
            "\n",
            "Epoch 00029: loss did not improve from 2.70379\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "Epoch 30/103\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            " - 64s - loss: 2.8168 - yolo_layer_1_loss: 1.3504 - yolo_layer_2_loss: 1.2310 - yolo_layer_3_loss: 0.2354\n",
            "\n",
            "Epoch 00030: loss did not improve from 2.70379\n",
            "Epoch 31/103\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            " - 63s - loss: 2.4477 - yolo_layer_1_loss: 1.4238 - yolo_layer_2_loss: 0.9074 - yolo_layer_3_loss: 0.1165\n",
            "\n",
            "Epoch 00031: loss improved from 2.70379 to 2.44767, saving model to raccoon.h5\n",
            "Epoch 32/103\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            " - 61s - loss: 2.5544 - yolo_layer_1_loss: 1.2612 - yolo_layer_2_loss: 1.0132 - yolo_layer_3_loss: 0.2800\n",
            "\n",
            "Epoch 00032: loss did not improve from 2.44767\n",
            "Epoch 33/103\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            " - 61s - loss: 2.9207 - yolo_layer_1_loss: 1.5185 - yolo_layer_2_loss: 1.0119 - yolo_layer_3_loss: 0.3902\n",
            "\n",
            "Epoch 00033: loss did not improve from 2.44767\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "Epoch 34/103\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            " - 68s - loss: 2.3260 - yolo_layer_1_loss: 1.6060 - yolo_layer_2_loss: 0.5672 - yolo_layer_3_loss: 0.1527\n",
            "\n",
            "Epoch 00034: loss improved from 2.44767 to 2.32600, saving model to raccoon.h5\n",
            "Epoch 35/103\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            " - 62s - loss: 2.5885 - yolo_layer_1_loss: 1.3392 - yolo_layer_2_loss: 0.9736 - yolo_layer_3_loss: 0.2757\n",
            "\n",
            "Epoch 00035: loss did not improve from 2.32600\n",
            "Epoch 36/103\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            " - 59s - loss: 3.1199 - yolo_layer_1_loss: 1.4363 - yolo_layer_2_loss: 1.3995 - yolo_layer_3_loss: 0.2841\n",
            "\n",
            "Epoch 00036: loss did not improve from 2.32600\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "Epoch 37/103\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            " - 69s - loss: 2.1338 - yolo_layer_1_loss: 1.2637 - yolo_layer_2_loss: 0.8361 - yolo_layer_3_loss: 0.0340\n",
            "\n",
            "Epoch 00037: loss improved from 2.32600 to 2.13376, saving model to raccoon.h5\n",
            "Epoch 38/103\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            " - 68s - loss: 2.6904 - yolo_layer_1_loss: 1.4774 - yolo_layer_2_loss: 1.1792 - yolo_layer_3_loss: 0.0338\n",
            "\n",
            "Epoch 00038: loss did not improve from 2.13376\n",
            "Epoch 39/103\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            " - 69s - loss: 2.9147 - yolo_layer_1_loss: 1.5380 - yolo_layer_2_loss: 1.2547 - yolo_layer_3_loss: 0.1219\n",
            "\n",
            "Epoch 00039: loss did not improve from 2.13376\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
            "Epoch 40/103\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            " - 73s - loss: 2.0463 - yolo_layer_1_loss: 1.3000 - yolo_layer_2_loss: 0.5057 - yolo_layer_3_loss: 0.2407\n",
            "\n",
            "Epoch 00040: loss improved from 2.13376 to 2.04632, saving model to raccoon.h5\n",
            "Epoch 41/103\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            " - 65s - loss: 3.0748 - yolo_layer_1_loss: 1.4962 - yolo_layer_2_loss: 1.3706 - yolo_layer_3_loss: 0.2080\n",
            "\n",
            "Epoch 00041: loss did not improve from 2.04632\n",
            "Epoch 42/103\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            " - 61s - loss: 2.9639 - yolo_layer_1_loss: 1.3409 - yolo_layer_2_loss: 1.4245 - yolo_layer_3_loss: 0.1985\n",
            "\n",
            "Epoch 00042: loss did not improve from 2.04632\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
            "Epoch 43/103\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            " - 56s - loss: 3.5080 - yolo_layer_1_loss: 1.3586 - yolo_layer_2_loss: 1.7967 - yolo_layer_3_loss: 0.3528\n",
            "\n",
            "Epoch 00043: loss did not improve from 2.04632\n",
            "Epoch 44/103\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            " - 62s - loss: 3.1080 - yolo_layer_1_loss: 1.4397 - yolo_layer_2_loss: 1.3815 - yolo_layer_3_loss: 0.2867\n",
            "\n",
            "Epoch 00044: loss did not improve from 2.04632\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
            "Epoch 45/103\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            " - 58s - loss: 2.7231 - yolo_layer_1_loss: 1.2855 - yolo_layer_2_loss: 1.2021 - yolo_layer_3_loss: 0.2355\n",
            "\n",
            "Epoch 00045: loss did not improve from 2.04632\n",
            "Epoch 46/103\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            " - 66s - loss: 2.7427 - yolo_layer_1_loss: 1.4799 - yolo_layer_2_loss: 1.0407 - yolo_layer_3_loss: 0.2221\n",
            "\n",
            "Epoch 00046: loss did not improve from 2.04632\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
            "Epoch 47/103\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            " - 61s - loss: 3.3567 - yolo_layer_1_loss: 1.5553 - yolo_layer_2_loss: 1.5658 - yolo_layer_3_loss: 0.2356\n",
            "\n",
            "Epoch 00047: loss did not improve from 2.04632\n",
            "Epoch 00047: early stopping\n",
            "raccoon: 0.9265\n",
            "mAP: 0.9265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "185rzO2_B4AK",
        "colab_type": "text"
      },
      "source": [
        "Sau khi quá trình huấn luyện kết thúc, hệ thống sẽ lưu mô hình raccoon.h5 trong thư mục của máy ảo colab. Ta có thể sửa lại mã nguồn của thư viện để các file mô hình và file trung gian đặt trong thư mục của thư viện cho gọn gàng.\n",
        "\n",
        "Sau đó, ta sẽ tiến hành thử nghiệm mô hình đã huấn luyện trên ảnh mẫu lấy từ mạng internet hoặc thư mục ảnh validation/train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBuMFKHAQNFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "dcce1e25-898b-470e-8430-c138af4cd822"
      },
      "source": [
        "!wget https://www.humanesociety.org/sites/default/files/styles/1240x698/public/2018/08/raccoon-440611.jpg"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-07 14:09:27--  https://www.humanesociety.org/sites/default/files/styles/1240x698/public/2018/08/raccoon-440611.jpg\n",
            "Resolving www.humanesociety.org (www.humanesociety.org)... 23.185.0.1, 2620:12a:8001::1, 2620:12a:8000::1\n",
            "Connecting to www.humanesociety.org (www.humanesociety.org)|23.185.0.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322378 (315K) [image/jpeg]\n",
            "Saving to: ‘raccoon-440611.jpg’\n",
            "\n",
            "\rraccoon-440611.jpg    0%[                    ]       0  --.-KB/s               \rraccoon-440611.jpg  100%[===================>] 314.82K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-08-07 14:09:27 (7.02 MB/s) - ‘raccoon-440611.jpg’ saved [322378/322378]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNy0y0fstq-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "outputId": "0fa52398-fe36-4b27-9a09-a482b6eb2951"
      },
      "source": [
        "!python $lab_path/predict.py -c $lab_path/zoo/config_raccoon.json -i raccoon-440611.jpg"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2020-08-07 14:09:47.629023: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-07 14:09:47.646754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 14:09:47.647448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-07 14:09:47.647761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-07 14:09:47.649295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-07 14:09:47.650471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-07 14:09:47.650830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-07 14:09:47.652513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-07 14:09:47.653607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-07 14:09:47.658136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-07 14:09:47.658268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 14:09:47.659139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 14:09:47.659775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-07 14:09:47.660217: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-08-07 14:09:47.665425: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2020-08-07 14:09:47.665653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d68d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-07 14:09:47.665690: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-07 14:09:47.720944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 14:09:47.721720: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d68f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-07 14:09:47.721756: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-08-07 14:09:47.722003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 14:09:47.722667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-07 14:09:47.722756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-07 14:09:47.722807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-07 14:09:47.722877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-07 14:09:47.722932: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-07 14:09:47.722980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-07 14:09:47.723028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-07 14:09:47.723076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-07 14:09:47.723198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 14:09:47.723972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 14:09:47.724625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-07 14:09:47.724698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-07 14:09:47.726082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-07 14:09:47.726118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-07 14:09:47.726148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-07 14:09:47.726348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 14:09:47.727113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-07 14:09:47.727733: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-07 14:09:47.727791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n",
            "raccoon-440611.jpg\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "2020-08-07 14:09:57.193930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-07 14:09:57.915129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty3gUk5tRJBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -R \"/content/raccoon.h5\" \"/content/gdrive/My Drive/Backup UIT\""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcHPECkzCZb7",
        "colab_type": "text"
      },
      "source": [
        "#3. Train trên bộ dữ liệu giao thông\n",
        "\n",
        "Như vậy, trong phần bài tập này chúng ta đã làm quen với thư viện keras-yolo3. Trong phần đồ án giữa kỳ, ta sẽ tiến hành trên dữ liệu video giao thông được thu tại TP. Hồ Chí Minh. Ví dụ, ảnh sau được cắt tại góc đường Nam Kỳ Khởi Nghĩa - Võ Thị Sáu.\n",
        "\n",
        "![alt text](https://i.imgur.com/NQBeNpG.jpg)\n",
        "\n",
        "Mục tiêu của đồ án này là sử dụng thuật toán YOLOv3 để tiến hành ước lượng lưu lượng giao thông theo các hướng đi.\n",
        "\n",
        "Đầu tiên, ta sẽ thử sử dụng pretrained model lên dữ liệu video thực tế.\n",
        "\n",
        "Sau đó tiến hành xây dựng bộ dữ liệu gán nhãn cho ngữ cảnh camera giao thông.\n",
        "\n",
        "Huấn luyện lại mô hình với dữ liệu gán nhãn mới.\n",
        "\n",
        "Phát hiện và đếm các đối tượng xe máy, xe hơi trong video giao thông.\n",
        "\n",
        "Video test: https://drive.google.com/file/d/1u__2tl79nSevF_pnvwsVd79Hu1aWLJQE/view?usp=sharing\n",
        "\n",
        "Tập ảnh dùng để train: https://drive.google.com/file/d/1-ZT6V2OrIWIWtLFFlizQBVvYxL__QFL7/view?usp=sharing\n",
        "\n"
      ]
    }
  ]
}